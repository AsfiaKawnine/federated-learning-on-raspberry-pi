{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Step - Predict!\n",
    "Great! We have successfully created our two models for bob and alice in parallel using federated learning! Let's try using our models for prediction now, shall we? This is the final reward for our endeavours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input_line, all_categories, worker, n_predictions=3):\n",
    "    \"\"\" \n",
    "    Uses :attr:`model` to predict top :attr:`n_predictions` categories \n",
    "    from :attr:`all_categories` for :attr:`input_line` using :attr:`worker`\n",
    "  \n",
    "    Parameters: \n",
    "        model (Module): model to be used for the prediction\n",
    "        input_line (str): input to the model\n",
    "        all_categories (list): list of all categories for the prediction\n",
    "        worker(BaseWorker): worker where the prediction will be performed\n",
    "        n_predictions(int): number of top predictions to return\n",
    "  \n",
    "    Returns: \n",
    "        list of tuples (value, category) sorted from max value to min\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    # copy the model to the worker only if is not already there\n",
    "    if model.location.id != worker.id:\n",
    "        model = model.copy().get()\n",
    "        model_remote = model.send(worker)\n",
    "    else:\n",
    "        model_remote = model\n",
    "    \n",
    "    # convert the input_line to a tensor and send it to the worker\n",
    "    line_tensor = lineToTensor(input_line)\n",
    "    line_remote = line_tensor.copy().send(worker)\n",
    "\n",
    "    # init the hidden layer\n",
    "    hidden = model_remote.initHidden()\n",
    "    hidden_remote = hidden.copy().send(worker)\n",
    "        \n",
    "    # get a result from the model\n",
    "    with torch.no_grad():\n",
    "        for i in range(line_remote.shape[0]):\n",
    "            output, hidden_remote = model_remote(line_remote[i], hidden_remote)\n",
    "    \n",
    "    # get top N categories\n",
    "    topv, topi = output.copy().get().topk(n_predictions, 1, True)\n",
    "\n",
    "    # construct list of (value, category) tuples\n",
    "    predictions = []\n",
    "    for i in range(n_predictions):\n",
    "        value = topv[0][i].item()\n",
    "        category_index = topi[0][i].item()\n",
    "        #print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "        predictions.append([value, all_categories[category_index]])\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the different models learned may perform different predictions, based on the data that was shown to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5791921615600586, 'Chinese'], [-1.1810355186462402, 'Korean'], [-3.452280282974243, 'Arabic']]\n"
     ]
    }
   ],
   "source": [
    "print(predict(model_pointers[\"alice\"], \"Qing\", all_categories,  alice) )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
