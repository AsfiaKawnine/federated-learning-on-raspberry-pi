{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FederatedLearningOnRaspberryPIs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGRdkGn7iUF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 --version\n",
        "!pip3 uninstall -y torch\n",
        "!pip3 uninstall -y torchvision\n",
        "!pip3 install torch==1.0.0\n",
        "!pip3 install torchvision==0.2.2.post3\n",
        "!pip3 install syft==0.1.13a1 --no-dependencies\n",
        "!pip3 install Flask flask-socketio lz4 websocket-client websockets zstd\n",
        "# Restart runtime option should popup, otherwise go to Runtime -> Restart runtime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2oW_FJYibER",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "803ed21a-9643-4641-bab5-00b31aefe303"
      },
      "source": [
        "!pip3 list | grep -E 'syft|torch'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "syft                     0.1.13a1             \n",
            "torch                    1.0.0                \n",
            "torchsummary             1.5.1                \n",
            "torchtext                0.3.1                \n",
            "torchvision              0.2.2.post3          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMf1JulmrMSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torch\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import string\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import math\n",
        "import syft as sy\n",
        "import pandas as pd\n",
        "import random\n",
        "from syft.frameworks.torch.federated import utils\n",
        "\n",
        "from syft.workers import WebsocketClientWorker\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQW0TeGprxcP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3bd730b9-575f-4b28-c0ec-23a22b8880c9"
      },
      "source": [
        "# Loading dataset\n",
        "!ls\n",
        "!wget https://download.pytorch.org/tutorial/data.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n",
            "--2019-08-13 17:42:10--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.224.2.123, 13.224.2.121, 13.224.2.111, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.224.2.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   2.75M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-08-13 17:42:10 (21.0 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7ylD-rFEtPc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "dccf3474-00ea-497e-9b8b-d0c4f48cc113"
      },
      "source": [
        "!unzip data.zip\n",
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "replace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/eng-fra.txt        \n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n",
            "data  data.zip\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfRtGt8GFlTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load all the files in a certain path\n",
        "def findFiles(path):\n",
        "    return glob.glob(path)\n",
        "\n",
        "# Read a file and split into lines\n",
        "def readLines(filename):\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "#convert a string 's' in unicode format to ASCII format\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join (\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01Z3MAOQFq-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "5fdc6c0e-e8f6-4878-a0fc-68f5bb892454"
      },
      "source": [
        "data_path = './data/names/*.txt'\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "for filename in findFiles(data_path):\n",
        "    print(filename)\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)\n",
        "    lines = readLines(filename)\n",
        "    category_lines[category] = lines   \n",
        "    \n",
        "n_categories = len(all_categories)\n",
        "\n",
        "print(\"Amount of categories:\" + str(n_categories))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./data/names/Chinese.txt\n",
            "./data/names/Dutch.txt\n",
            "./data/names/Czech.txt\n",
            "./data/names/Vietnamese.txt\n",
            "./data/names/Polish.txt\n",
            "./data/names/Irish.txt\n",
            "./data/names/Korean.txt\n",
            "./data/names/Arabic.txt\n",
            "./data/names/Portuguese.txt\n",
            "./data/names/Greek.txt\n",
            "./data/names/Spanish.txt\n",
            "./data/names/Japanese.txt\n",
            "./data/names/Italian.txt\n",
            "./data/names/French.txt\n",
            "./data/names/Russian.txt\n",
            "./data/names/English.txt\n",
            "./data/names/German.txt\n",
            "./data/names/Scottish.txt\n",
            "Amount of categories:18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbCNl5vOG7Q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LanguageDataset(Dataset):\n",
        "    #Constructor is mandatory\n",
        "        def __init__(self, text, labels, transform=None):\n",
        "            self.data = text\n",
        "            self.targets = labels #categories\n",
        "            #self.to_torchtensor()\n",
        "            self.transform = transform\n",
        "        \n",
        "        def to_torchtensor(self):            \n",
        "            self.data = torch.from_numpy(self.text, requires_grad=True)\n",
        "            self.labels = torch.from_numpy(self.targets, requires_grad=True)\n",
        "        \n",
        "        def __len__(self):\n",
        "            #Mandatory\n",
        "            '''Returns:\n",
        "                    Length [int]: Length of Dataset/batches\n",
        "            '''\n",
        "            return len(self.data)\n",
        "    \n",
        "        def __getitem__(self, idx): \n",
        "            #Mandatory \n",
        "            \n",
        "            '''Returns:\n",
        "                     Data [Torch Tensor]: \n",
        "                     Target [ Torch Tensor]:\n",
        "            '''\n",
        "            sample = self.data[idx]\n",
        "            target = self.targets[idx]\n",
        "                    \n",
        "            if self.transform:\n",
        "                sample = self.transform(sample)\n",
        "    \n",
        "            return sample,target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQba15YQHYR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The list of arguments for our program. We will be needing most of them soon.\n",
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 1\n",
        "        self.learning_rate = 0.005\n",
        "        self.epochs = 10000\n",
        "        self.federate_after_n_batches = 15000\n",
        "        self.seed = 1\n",
        "        self.print_every = 200\n",
        "        self.plot_every = 100\n",
        "        self.use_cuda = False\n",
        "        \n",
        "args = Arguments()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u34QkoBkHlb0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8311180e-e4ca-4dc8-a48d-8b932204716f"
      },
      "source": [
        "%%latex\n",
        "\n",
        "\\begin{split}\n",
        "names\\_list = [d_1,...,d_n]  \\\\\n",
        "\n",
        "category\\_list = [c_1,...,c_n] \n",
        "\\end{split}\n",
        "\n",
        "\n",
        "Where $n$ is the total amount of data points"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/latex": "\n\\begin{split}\nnames\\_list = [d_1,...,d_n]  \\\\\n\ncategory\\_list = [c_1,...,c_n] \n\\end{split}\n\n\nWhere $n$ is the total amount of data points",
            "text/plain": [
              "<IPython.core.display.Latex object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0aZBnZEHpfH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c485476b-d3d3-4b14-f1c1-b6443eefc7cb"
      },
      "source": [
        "#Set of names(X)\n",
        "names_list = []\n",
        "#Set of labels (Y)\n",
        "category_list = []\n",
        "\n",
        "#Convert into a list with corresponding label.\n",
        "\n",
        "for nation, names in category_lines.items():\n",
        "    #iterate over every single name\n",
        "    for name in names:\n",
        "        names_list.append(name)      #input data point\n",
        "        category_list.append(nation) #label\n",
        "        \n",
        "#let's see if it was successfully loaded. Each data sample(X) should have its own corresponding category(Y)\n",
        "print(names_list[1:20])\n",
        "print(category_list[1:20])\n",
        "\n",
        "print(\"\\n \\n Amount of data points loaded: \" + str(len(names_list)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['AuYong', 'Bai', 'Ban', 'Bao', 'Bei', 'Bian', 'Bui', 'Cai', 'Cao', 'Cen', 'Chai', 'Chaim', 'Chan', 'Chang', 'Chao', 'Che', 'Chen', 'Cheng', 'Cheung']\n",
            "['Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese']\n",
            "\n",
            " \n",
            " Amount of data points loaded: 20074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5QXRytdH2NQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bbf5de9a-0e8a-4123-c023-794b8a409688"
      },
      "source": [
        "#Assign an integer to every category\n",
        "categories_numerical = pd.factorize(category_list)[0]\n",
        "#Let's wrap our categories with a tensor, so that it can be loaded by LanguageDataset\n",
        "category_tensor = torch.tensor(np.array(categories_numerical), dtype=torch.long)\n",
        "#Ready to be processed by torch.from_numpy in LanguageDataset\n",
        "categories_numpy = np.array(category_tensor)\n",
        "\n",
        "#Let's see a few resulting categories\n",
        "print(names_list[1200:1210])\n",
        "print(categories_numpy[1200:1210])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Kaluza', 'Kaminski', 'Kasprzak', 'Kava', 'Kedzierski', 'Kijek', 'Klimek', 'Kosmatka', 'Kowalczyk', 'Kowalski']\n",
            "[4 4 4 4 4 4 4 4 4 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uFEKcRYH8np",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "bc9db229-132f-402e-b69c-59c47099e5f2"
      },
      "source": [
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter)\n",
        "    \n",
        "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
        "def letterToTensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    tensor[0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>,\n",
        "# or an array of one-hot letter vectors\n",
        "def lineToTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters) #Daniele: len(max_line_size) was len(line)\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "    #Daniele: add blank elements over here\n",
        "    return tensor    \n",
        "    \n",
        "    \n",
        "    \n",
        "def list_strings_to_list_tensors(names_list):\n",
        "    lines_tensors = []\n",
        "    for index, line in enumerate(names_list):\n",
        "        lineTensor = lineToTensor(line)\n",
        "        lineNumpy = lineTensor.numpy()\n",
        "        lines_tensors.append(lineNumpy)\n",
        "        \n",
        "    return(lines_tensors)\n",
        "\n",
        "lines_tensors = list_strings_to_list_tensors(names_list)\n",
        "\n",
        "print(names_list[0])\n",
        "print(lines_tensors[0])\n",
        "print(lines_tensors[0].shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ang\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "(3, 1, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y575umqqJVI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "888a24cc-6638-4a79-cce8-24b246a6aa8f"
      },
      "source": [
        "max_line_size = max(len(x) for x in lines_tensors)\n",
        "\n",
        "def lineToTensorFillEmpty(line, max_line_size):\n",
        "    tensor = torch.zeros(max_line_size, 1, n_letters) #notice the difference between this method and the previous one\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "        \n",
        "        #Vectors with (0,0,.... ,0) are placed where there are no characters\n",
        "    return tensor\n",
        "\n",
        "def list_strings_to_list_tensors_fill_empty(names_list):\n",
        "    lines_tensors = []\n",
        "    for index, line in enumerate(names_list):\n",
        "        lineTensor = lineToTensorFillEmpty(line, max_line_size)\n",
        "        lines_tensors.append(lineTensor)\n",
        "    return(lines_tensors)\n",
        "\n",
        "lines_tensors = list_strings_to_list_tensors_fill_empty(names_list)\n",
        "\n",
        "#Let's take a look at what a word now looks like\n",
        "print(names_list[0])\n",
        "print(lines_tensors[0])\n",
        "print(lines_tensors[0].shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ang\n",
            "tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]]])\n",
            "torch.Size([19, 1, 57])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDS_xjBlIAax",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "960956d6-666a-43db-eb45-8a81ac5e578c"
      },
      "source": [
        "#And finally, from a list, we can create a numpy array with all our word embeddings having the same shape:\n",
        "array_lines_tensors = np.stack(lines_tensors)\n",
        "#However, such operation introduces one extra dimension (look at the dimension with index=2 having size '1')\n",
        "print(array_lines_tensors.shape)\n",
        "#Because that dimension just has size 1, we can get rid of it with the following function call\n",
        "array_lines_proper_dimension = np.squeeze(array_lines_tensors, axis=2)\n",
        "print(array_lines_proper_dimension.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20074, 19, 1, 57)\n",
            "(20074, 19, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1UD93dXIVhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cd46650c-c45a-4b96-fce2-9b0b6d211c1c"
      },
      "source": [
        "\n",
        "def find_start_index_per_category(category_list):\n",
        "    categories_start_index = {}\n",
        "    \n",
        "    #Initialize every category with an empty list\n",
        "    for category in all_categories:\n",
        "        categories_start_index[category] = []\n",
        "    \n",
        "    #Insert the start index of each category into the dictionary categories_start_index\n",
        "    #Example: \"Italian\" --> 203\n",
        "    #         \"Spanish\" --> 19776\n",
        "    last_category = None\n",
        "    i = 0\n",
        "    for name in names_list:\n",
        "        cur_category = category_list[i]\n",
        "        if(cur_category != last_category):\n",
        "            categories_start_index[cur_category] = i\n",
        "            last_category = cur_category\n",
        "        \n",
        "        i = i + 1\n",
        "        \n",
        "    return(categories_start_index)\n",
        "\n",
        "categories_start_index = find_start_index_per_category(category_list)\n",
        "\n",
        "print(categories_start_index)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Chinese': 0, 'Dutch': 268, 'Czech': 565, 'Vietnamese': 1084, 'Polish': 1157, 'Irish': 1296, 'Korean': 1528, 'Arabic': 1622, 'Portuguese': 3622, 'Greek': 3696, 'Spanish': 3899, 'Japanese': 4197, 'Italian': 5188, 'French': 5897, 'Russian': 6174, 'English': 15582, 'German': 19250, 'Scottish': 19974}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlk_lLPSJ0n-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomChoice(l):\n",
        "    rand_value = random.randint(0, len(l) - 1)\n",
        "    return l[rand_value], rand_value\n",
        "\n",
        "\n",
        "def randomTrainingIndex():\n",
        "    category, rand_cat_index = randomChoice(all_categories) #cat = category, it's not a random animal\n",
        "    #rand_line_index is a relative index for a data point within the random category rand_cat_index\n",
        "    line, rand_line_index = randomChoice(category_lines[category])\n",
        "    category_start_index = categories_start_index[category]\n",
        "    absolute_index = category_start_index + rand_line_index\n",
        "    return(absolute_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSZ3_EKmJ9v6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 3. Step: Model - Recurrent Neural Network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnElNc76KQrs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cffc819c-3858-47b2-b79c-d11004454f7d"
      },
      "source": [
        "#Two hidden layers, based on simple linear layers\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "#Let's instantiate the neural network already:\n",
        "n_hidden = 128\n",
        "#Instantiate RNN\n",
        "\n",
        "device = torch.device(\"cuda\" if args.use_cuda else \"cpu\")\n",
        "model = RNN(n_letters, n_hidden, n_categories).to(device)\n",
        "#The final softmax layer will produce a probability for each one of our 18 categories\n",
        "print(model)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (i2h): Linear(in_features=185, out_features=128, bias=True)\n",
            "  (i2o): Linear(in_features=185, out_features=18, bias=True)\n",
            "  (softmax): LogSoftmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPIjPtnuKmc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now let's define our workers. You can either use remote workers or virtual workers\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  \n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  \n",
        "#charlie = sy.VirtualWorker(hook, id=\"charlie\") \n",
        "\n",
        "workers_virtual = [alice, bob]\n",
        "\n",
        "#If you have your workers operating remotely, like on Raspberry PIs\n",
        "#kwargs_websocket_alice = {\"host\": \"ip_alice\", \"hook\": hook}\n",
        "#alice = WebsocketClientWorker(id=\"alice\", port=8777, **kwargs_websocket_alice)\n",
        "#kwargs_websocket_bob = {\"host\": \"ip_bob\", \"hook\": hook}\n",
        "#bob = WebsocketClientWorker(id=\"bob\", port=8778, **kwargs_websocket_bob)\n",
        "#workers_virtual = [alice, bob]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTjDBCOkKxG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#array_lines_proper_dimension = our data points(X)\n",
        "#categories_numpy = our labels (Y)\n",
        "langDataset =  LanguageDataset(array_lines_proper_dimension, categories_numpy)\n",
        "\n",
        "#assign the data points and the corresponding categories to workers.\n",
        "federated_train_loader = sy.FederatedDataLoader(\n",
        "            langDataset\n",
        "            .federate(workers_virtual),\n",
        "            batch_size=args.batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZTu8CPEK1W-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 4. Step - Model Training!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7svbudkK6aG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    return all_categories[category_i], category_i\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def fed_avg_every_n_iters(model_pointers, iter, federate_after_n_batches):\n",
        "        models_local = {}\n",
        "        \n",
        "        if(iter % args.federate_after_n_batches == 0):\n",
        "            for worker_name, model_pointer in model_pointers.items():\n",
        "#                #need to assign the model to the worker it belongs to.\n",
        "                models_local[worker_name] = model_pointer.copy().get()\n",
        "            model_avg = utils.federated_avg(models_local)\n",
        "           \n",
        "            for worker in workers_virtual:\n",
        "                model_copied_avg = model_avg.copy()\n",
        "                model_ptr = model_copied_avg.send(worker) \n",
        "                model_pointers[worker.id] = model_ptr\n",
        "                \n",
        "        return(model_pointers)     \n",
        "\n",
        "def fw_bw_pass_model(model_pointers, line_single, category_single):\n",
        "    #get the right initialized model\n",
        "    model_ptr = model_pointers[line_single.location.id]   \n",
        "    line_reshaped = line_single.reshape(max_line_size, 1, len(all_letters))\n",
        "    line_reshaped, category_single = line_reshaped.to(device), category_single.to(device)\n",
        "    #Firstly, initialize hidden layer\n",
        "    hidden_init = model_ptr.initHidden() \n",
        "    #And now zero grad the model\n",
        "    model_ptr.zero_grad()\n",
        "    hidden_ptr = hidden_init.send(line_single.location)\n",
        "    amount_lines_non_zero = len(torch.nonzero(line_reshaped.copy().get()))\n",
        "    #now need to perform forward passes\n",
        "    for i in range(amount_lines_non_zero): \n",
        "        output, hidden_ptr = model_ptr(line_reshaped[i], hidden_ptr) \n",
        "    criterion = nn.NLLLoss()   \n",
        "    loss = criterion(output, category_single) \n",
        "    loss.backward()\n",
        "    \n",
        "    model_got = model_ptr.get() \n",
        "    \n",
        "    #Perform model weights' updates    \n",
        "    for param in model_got.parameters():\n",
        "        param.data.add_(-args.learning_rate, param.grad.data)\n",
        "        \n",
        "        \n",
        "    model_sent = model_got.send(line_single.location.id)\n",
        "    model_pointers[line_single.location.id] = model_sent\n",
        "    \n",
        "    return(model_pointers, loss, output)\n",
        "            \n",
        "  \n",
        "    \n",
        "def train_RNN(n_iters, print_every, plot_every, federate_after_n_batches, list_federated_train_loader):\n",
        "    current_loss = 0\n",
        "    all_losses = []    \n",
        "    \n",
        "    model_pointers = {}\n",
        "    \n",
        "    #Send the initialized model to every single worker just before the training procedure starts\n",
        "    for worker in workers_virtual:\n",
        "        model_copied = model.copy()\n",
        "        model_ptr = model_copied.send(worker) \n",
        "        model_pointers[worker.id] = model_ptr\n",
        "\n",
        "    #extract a random element from the list and perform training on it\n",
        "    for iter in range(1, n_iters + 1):        \n",
        "        random_index = randomTrainingIndex()\n",
        "        line_single, category_single = list_federated_train_loader[random_index]\n",
        "        #print(category_single.copy().get())\n",
        "        line_name = names_list[random_index]\n",
        "        model_pointers, loss, output = fw_bw_pass_model(model_pointers, line_single, category_single)\n",
        "        #model_pointers = fed_avg_every_n_iters(model_pointers, iter, args.federate_after_n_batches)\n",
        "        #Update the current loss a\n",
        "        loss_got = loss.get().item() \n",
        "        current_loss += loss_got\n",
        "        \n",
        "        if iter % plot_every == 0:\n",
        "            all_losses.append(current_loss / plot_every)\n",
        "            current_loss = 0\n",
        "             \n",
        "        if(iter % print_every == 0):\n",
        "            output_got = output.get()  #Without copy()\n",
        "            guess, guess_i = categoryFromOutput(output_got)\n",
        "            category = all_categories[category_single.copy().get().item()]\n",
        "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "            print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss_got, line_name, guess, correct))\n",
        "    return(all_losses, model_pointers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGole52rK-mT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22ba8e6d-6435-4b65-e325-df9914c3f872"
      },
      "source": [
        "#This may take a few seconds to complete.\n",
        "print(\"Generating list of batches for the workers...\")\n",
        "list_federated_train_loader = list(federated_train_loader)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating list of batches for the workers...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyE8mZl9LA1j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "6ef8285c-0ce1-499f-8227-b8734688628f"
      },
      "source": [
        "start = time.time()\n",
        "all_losses, model_pointers = train_RNN(args.epochs, args.print_every, args.plot_every, args.federate_after_n_batches, list_federated_train_loader)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200 2% (0m 13s) 2.8212 Michalaras / Dutch ✗ (Greek)\n",
            "400 4% (0m 18s) 2.9607 Poplawski / Vietnamese ✗ (Polish)\n",
            "600 6% (0m 22s) 2.4925 Cummins / English ✓\n",
            "800 8% (0m 26s) 2.7495 Seif / Greek ✗ (Arabic)\n",
            "1000 10% (0m 31s) 2.8103 Caiazzo / French ✗ (Italian)\n",
            "1200 12% (0m 35s) 2.6350 Zeng / Chinese ✓\n",
            "1400 14% (0m 40s) 2.3222 Xydis / Greek ✓\n",
            "1600 16% (0m 44s) 2.5542 Segher / French ✗ (Dutch)\n",
            "1800 18% (0m 49s) 2.9289 Maria / Italian ✗ (Portuguese)\n",
            "2000 20% (0m 53s) 2.7892 Kouri / Italian ✗ (Arabic)\n",
            "2200 22% (0m 58s) 2.6130 Ubina / Czech ✗ (Spanish)\n",
            "2400 24% (1m 2s) 2.4149 Demall / Czech ✓\n",
            "2600 26% (1m 6s) 2.6172 Marion / Irish ✗ (French)\n",
            "2800 28% (1m 11s) 2.9326 Stabile / Irish ✗ (Italian)\n",
            "3000 30% (1m 15s) 2.6873 Berger / Arabic ✗ (French)\n",
            "3200 32% (1m 20s) 1.4597 Cameron / English ✗ (Scottish)\n",
            "3400 34% (1m 24s) 1.0064 Tableriou / Greek ✓\n",
            "3600 36% (1m 28s) 1.9241 Ngai / Chinese ✗ (Korean)\n",
            "3800 38% (1m 33s) 2.5031 Cearbhall / Greek ✗ (Irish)\n",
            "4000 40% (1m 37s) 2.7807 Marie / Arabic ✗ (French)\n",
            "4200 42% (1m 42s) 2.3524 Moghadam / French ✗ (Arabic)\n",
            "4400 44% (1m 46s) 1.9173 Kurkawa / Japanese ✓\n",
            "4600 46% (1m 51s) 1.8719 Seo / Chinese ✗ (Korean)\n",
            "4800 48% (1m 55s) 1.7282 Nam / Chinese ✗ (Korean)\n",
            "5000 50% (2m 0s) 1.0884 Geracimos / Greek ✓\n",
            "5200 52% (2m 4s) 2.2646 Baglio / Portuguese ✗ (Italian)\n",
            "5400 54% (2m 9s) 1.6353 Nikolaou / Greek ✓\n",
            "5600 56% (2m 13s) 2.0751 Takayama / Japanese ✓\n",
            "5800 57% (2m 18s) 2.4650 Mayuzumi / Italian ✗ (Japanese)\n",
            "6000 60% (2m 22s) 1.5639 Zheng / Chinese ✓\n",
            "6200 62% (2m 26s) 1.5727 Mateus / Portuguese ✓\n",
            "6400 64% (2m 31s) 1.7758 Kowalczyk / Polish ✓\n",
            "6600 66% (2m 35s) 1.3634 Roth / English ✗ (German)\n",
            "6800 68% (2m 40s) 1.9729 Talpin / Scottish ✗ (Russian)\n",
            "7000 70% (2m 44s) 1.4252 Mccallum / English ✗ (Scottish)\n",
            "7200 72% (2m 49s) 1.3146 Papageorge / Greek ✓\n",
            "7400 74% (2m 53s) 2.1818 Kaplanek / Polish ✗ (Czech)\n",
            "7600 76% (2m 58s) 2.3010 Huynh / Arabic ✗ (Vietnamese)\n",
            "7800 78% (3m 3s) 1.7554 Whalen / Irish ✓\n",
            "8000 80% (3m 7s) 2.3863 Gaspar / Arabic ✗ (Spanish)\n",
            "8200 82% (3m 12s) 1.4691 Luc / Chinese ✗ (Vietnamese)\n",
            "8400 84% (3m 16s) 2.3771 Amador / Arabic ✗ (Spanish)\n",
            "8600 86% (3m 20s) 1.4296 Chu / Chinese ✗ (Vietnamese)\n",
            "8800 88% (3m 25s) 2.2629 Cardozo / Italian ✗ (Portuguese)\n",
            "9000 90% (3m 29s) 1.8298 Zientek / Polish ✓\n",
            "9200 92% (3m 34s) 1.8583 Hassel / Dutch ✓\n",
            "9400 94% (3m 38s) 1.2434 Lieu / Vietnamese ✓\n",
            "9600 96% (3m 43s) 2.0437 Kagabu / Japanese ✓\n",
            "9800 98% (3m 47s) 1.5530 Le / Vietnamese ✓\n",
            "10000 100% (3m 51s) 2.7336 Torres / Dutch ✗ (Spanish)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDjZMoPHLEsc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "85f252c9-cbfa-4efc-d256-22752d83c572"
      },
      "source": [
        "#Let's plot the loss we got during the training procedure\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel('Epochs (100s)')\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fda95faa2e8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl83HW56PHPM9mXyb41W5M23UvX\nAIUWaMsOiqgIbqAoclBUXI/bvXr06L3Xg3oQUZEDiijiAkVZlL0ihZLSvU3btGnSJfu+75nv/eM3\nM5kkk2TSZDJZnvfrlReTX74z8wwD88x3e75ijEEppZQCsAU6AKWUUtOHJgWllFJumhSUUkq5aVJQ\nSinlpklBKaWUmyYFpZRSbpoUlFJKuWlSUEop5aZJQSmllFtwoAMYr6SkJJOTkxPoMJRSakbZs2dP\nnTEmeax2My4p5OTksHv37kCHoZRSM4qInPalnQ4fKaWUctOkoJRSyk2TglJKKTdNCkoppdw0KSil\nlHLTpKCUUspNk4JSSim3OZMUalu7+Y9nCunpcwQ6FKWUmrbmTFLYVdrAo2+d4qtPHsDh0HOplVLK\nmxm3o/lcXb9qHqfql3Dvi0WkxYbzjWuXBTokpZSaduZMUgD4zOaFVDZ38qvXS5gXE87HN+YGOiSl\nlJpW5szwEYCI8N0bVnLl8lS++9wR9p5pDHRISik1rcyppAAQZBPuu2UN8ZGh/OzVE4EORymlppU5\nlxQAosKC+eSmXLYX1XKorDnQ4Sil1LQxJ5MCwG0XzScmPJgHtmtvQSmlXOZsUrCHh/Dxjbm8WFhN\nUVVroMNRSqlpYc4mBYDbL84hKjSIB7YXBzoUpZSaFuZ0UoiPCuWjF83nuYMV3P/qCQ6WNenGNqXU\nnDankwLAnZcsYH12PD95+Tg3PPAmF/yfVygoqQ90WEopFRBzPikkRofx5Kcv5p1vXcF/37KaiNAg\nvvH0Ia2RpJSak+Z8UnBJtofx3rWZfO+GlZTUtvPYzlOBDkkppaacJoUhtixNYevSFO575QQ1rV2B\nDkcppaaU35KCiGSJyHYROSIihSJyj5c2sSLyrIgccLa53V/xjMf/ftdyuvv6ufeFokCHopRSU8qf\nPYU+4MvGmOXABuBuEVk+pM3dwBFjzGpgM/BjEQn1Y0w+yU2K4hObcvnLnjIeLzhNe3dfoENSSqkp\n4bcqqcaYSqDSebtVRI4CGcARz2aAXUQEiAYasJJJwH1u6yJeL6rlW08f5vvPHeWalWmk2MNo7Oih\nubOXW87PYuvS1ECHqZRSk2pKSmeLSA6wFigY8qcHgGeACsAO3GKMGbbsR0TuBO4EyM7O9meobtFh\nwfzjnkvYfbqRbXvLee5gBd29DuIiQ2jv7qOyuUuTglJq1hFj/LtZS0SigdeBHxhjtg35203ARuBL\nwELgZWC1MaZlpMfLz883u3fv9mPE3rn+PYkIv/znSX74wjHe+vpW0uMipjwWpZQaLxHZY4zJH6ud\nX1cfiUgI8BTw+NCE4HQ7sM1YioFSYKk/YzpXIoI1ygVXrbB6CC8fqR7UprG9h4b2nimPTSmlJos/\nVx8J8Ahw1BjzkxGanQEud7ZPBZYAJf6KabIsTI5mYXIULx2pcl9zOAwffriATz029b0YpZSaLP6c\nU9gI3AocEpH9zmvfBLIBjDEPAv8JPCoihwABvmaMqfNjTJPm6hVp/OpfJTR19BAXGcorR6s5WtmC\nCO5rSik10/hz9dEOrA/60dpUAFf5KwZ/umpFGr/450leO1bDe9dm8MD2YqJCg2jv6WfnyXquPW9e\noENUSqlx0x3N52hVRiypMWG8VFjNv07UcbCsmW9ct4zosGDeKJ4RnR2llBpmSpakzkY2m3DV8jSe\n3FNGZUsX6bHh3JyfxT+LanhTk4JSaobSnsIEXLUilc7efg6cbeKuzQsJDbaxKS+J0/UdnG3oCHR4\nSik1bpoUJuDC3ETs4cEk28O4OT8LgE2LkgDYob0FpdQMpMNHExAabOPem1YTEx5MeEgQYC1XTYsJ\nZ8eJOj50wdTsvlZKqcmiSWGCrlmZNuh3EWFjXhKvHqvG4TDYbKMuwFJKqWlFh4/84JJFSTR19FJY\nMWK1DqWUmpY0KfjBxXmJgM4rKKVmHk0KfpBiD2dJqp2/7S+nvKkz0OEopZTPNCn4yac3L6S0rp2t\nP/on//XCMVq7egMdklJKjUmTgp/cuDaD176ymWtXWuUw3vPAm3T19gc6LKWUGpUmBT/KiIvgvg+u\n5ZGP5VNS184jO0oDHZJSSo1Kk8IUuHxZKlctT+UX24upaekKdDhKKTUiTQpT5JvXLaOn38GPXioK\ndChKKTUiTQpTJCcpits35vKXPWUcLm8OdDhKKeWVJoUp9NmteSREhvK9544EOhSllPJKk8IUigkP\n4TNb8thV2kBRVWugw1FKqWE0KUyxG1anYxN45kB5oENRSqlhNClMsWR7GBvzknj2QCXGmECHo5RS\ng2hSCIB3r07nTEMH+882BToUpZQaRJNCAFy9Io3QIBvPHKgIdChKKTWIJoUAiI0IYfOSZJ4/WEm/\nQ4eQlFLThyaFALlhTTo1rd0UlNYHOhSllHLTpBAgly9NJSo0iGcPVGCMoaG9h2otgaGUCjA9jjNA\nIkKDuHJ5Kn/ZXcZf91XQ2dtPkE14/aubyYyPDHR4Sqk5ym9JQUSygMeAVMAADxljfuql3WbgPiAE\nqDPGXOavmKabuzYvxABJ0WGEh9j4+faT7Cpt0KSglAoYf/YU+oAvG2P2iogd2CMiLxtj3DUeRCQO\n+AVwjTHmjIik+DGeaWdpWgw//eBaAPodhsfeOs3u0428b11mgCNTSs1VfptTMMZUGmP2Om+3AkeB\njCHNPgxsM8accbar8Vc8012QTVg7P569pxsDHYpSag6bkolmEckB1gIFQ/60GIgXkX+KyB4RuW0q\n4pmu1mfHU1TdSose3amUChC/JwURiQaeAr5gjGkZ8udgYD1wPXA18L9FZLGXx7hTRHaLyO7a2lp/\nhxww6+fHYwzsO6M7nZVSgeHXpCAiIVgJ4XFjzDYvTcqAF40x7caYOuBfwOqhjYwxDxlj8o0x+cnJ\nyf4MOaDWZMdhE9ijQ0hKqQDxW1IQEQEeAY4aY34yQrO/AZtEJFhEIoELseYe5qTosGCWpsWc07zC\nO6caaGzv8UNUSqm5xJ89hY3ArcBWEdnv/LlORO4SkbsAjDFHgReAg8Au4GFjzGE/xjTtrZ8fz74z\njfT1O3y+T0dPHx966G1+82apHyNTSs0FfluSaozZAYgP7e4F7vVXHDNNfk48v3v7NEXVraxIj/Xp\nPsU1bfQ5DOVNuiNaKTUxWuZimlmXHQ+Mb17heHUbADWtmhSUUhOjSWGayYyPIMUeNq6kcKLaOtpT\naycppSZKk8I0IyLk58SPLynUWD2F6pZuf4WllJojNClMQ+uy4ylr7KSyudOn9sedPYXmzl66evv9\nGZpSapbTpDANbVmaggj8esfYq4nau/soa+wkO8Eqolfbqr0FpdS506QwDS1MjuZ9azP57c7TVDSN\n3lsodg4dbcxLAnReQSk1MZoUpqkvXrkIDNz3yvFR27mGji5ZZCWFGu0pKKUmQJPCNJUZH8mtF83n\nyT1l7tVF3pyoaSM0yEZ+jrWUVXsKSqmJ0KQwjd29JY+o0GB+9FLRiG1OVLeyIDmK5OgwQoJEVyAp\npSZEk8I0lhAVyp2XLuDFwmqOVAwtMGs5Xt3G4lQ7IkKKPZwa7SkopSZAk8I0d+Na61yiA2XDy2m3\nd/dR3tTJ4tRoAFJiwnROQSk1IZoUprmMuAhCg22U1LYN+5tr09qiVDsAqfZwnVNQSk2IJoVpzmYT\nchOjKK1rH/Y318qjxc6kkBITpklBKTUhmhRmgAXJUZR4SQonqlsJDba5N66lxoTT0tWnu5qVUudM\nk8IMkJsUxZn6DnqHnLFwoqaNhcnRBNmsCuUp9jAAanQFklLqHGlSmAEWJEfT5zCUNQ7e3Xyius09\nyQyQEhMOQLWW0FZKnSNNCjNAblIUwKDJ5pauXufKI7v7WmqM1VPQeQWl1LnSpDADLHAmBc/J5gNn\nrSWqqzIHTmdLtVs9BR0+UkqdK00KM0B8VCjxkSGDJpv3nm5CBNZkxbmvxUWGEBpk0+EjpdQ506Qw\nQ+QmRQ0aPtpzppElqXbs4SHuayJCsj1MewpKqXOmSWGGWJAc7R4+cjgM+043sm5+/LB2qbpXQSk1\nAZoUZojcpCiqW7pp6+7jRE0brd19rM/2lhTCtdSFUuqcaVKYIVyTzafq2t3nN6/32lPQUhdKqXOn\nSWGGWJBs7UcocSaFxKhQ5idGDmuXbA+jtauPzh7d1ayUGj9NCjPE/MRIRKy9CnvPWPMJIjKsXapz\nA1uNrkBSSp0DTQozRHhIEBlxEew53UhpXbvXoSPw3MBmzSv0Owx9Q8pjKKXUSPyWFEQkS0S2i8gR\nESkUkXtGaXu+iPSJyE3+imc2yE2KYkdxHeB9PgEGegrVLV3sOFHHhf/nFb7//NEpi1EpNbMF+/Gx\n+4AvG2P2iogd2CMiLxtjjng2EpEg4IfAS36MZVZYkBTFGyfqCAkSzsuI9drGVRTvwddPcqSyBWPg\nTWciUUqpsfitp2CMqTTG7HXebgWOAhlemn4OeAqo8Vcss4Vrsnl5eizhIUFe28RGhBAabKOwooX3\nrc3kjk25nKxt03LaSimfTMmcgojkAGuBgiHXM4D3Ar+cijhmOldhPG/7E1xEhG9cu5T7blnDj29e\nzfr58TjMwIE8Sik1Gn8OHwEgItFYPYEvGGOGnj5/H/A1Y4zD20oaj8e4E7gTIDs721+hTnsr0mOI\niwzhimUpo7a7fWOu+/by9BgAjlS0sCozbqS7KKUU4OekICIhWAnhcWPMNi9N8oE/OhNCEnCdiPQZ\nY/7q2cgY8xDwEEB+fr7xZ8zTWWJ0GPu/fdW47pMVH0l0WDBHKofmY6WUGs5vSUGsT/pHgKPGmJ94\na2OMyfVo/yjw3NCEoCbGZhOWptk5qklBKeUDn+YURGShiIQ5b28Wkc+LyFhjERuBW4GtIrLf+XOd\niNwlIndNMG41DsvTYzha2YrD4d9OlsNheP5gJd19Oqmt1Ezl60TzU0C/iORhDeNkAX8Y7Q7GmB3G\nGDHGrDLGrHH+/N0Y86Ax5kEv7T9ujHly3K9AjWn5vBjauvs429jh1+d59VgNd/9hLy8crvLr8yil\n/MfXpOAwxvRhrRT6mTHmq8A8/4WlJtOyedZks7+HkJ7ccxaAU3X+TT5KKf/xNSn0isiHgI8Bzzmv\nhYzSXk0jS9Ls2MRageQvDe09vHbM2mpypkGTglIzla9J4XbgIuAHxphSEckFfue/sNRkCg8JYmFy\ntF9XID2zv5zefkOyPYyzmhSUmrF8Wn3kLE3xeQARiQfsxpgf+jMwNbmWp8fwTmmD3x7/yb1lrMyI\nYUlqjJbVUGoG83X10T9FJEZEEoC9wP+IiNdlpmp6WjYvhormLpo6eob9bXtRDV/+8wF+vr2Yl49U\nU97UOa7HPlbVwuHyFm5al0l2QiRVLV1aVkOpGcrXfQqxxpgWEbkDeMwY8x0ROejPwNTkWu6cbD5S\n2cLFC5MG/e3HLxVxrLKVPo8lqzmJkWzMS+KG1elcuCBx1Md+ak8ZIUHCDWsyeP24Na9Q1thJXkr0\nJL8KpZS/+TqnECwi84CbGZhoVjOIawXS0MnmssYODpe38JWrl3DoP65i22cu5tvvWk5eSjR/3VfO\nhx8uoLJ55J5Db7+Dp/dVsHVpCglRoWQnWKfB+Xv5q1LKP3xNCt8DXgROGmPeEZEFwAn/haUmW7I9\njGR72LDJ5hcLqwG4ekUa9vAQ1mXH84lNuTz8sfN59nOb6HcY/nFo5H0Hb52sp66tm/evywQgy5UU\ndLJZqRnJp6RgjPmLcxPap52/lxhj3u/f0NRk27AgkVeOVNPW3ee+9mJhFUtS7e4KrJ4WJEezNM3O\n3w9VjviYrx2tJjzExqWLkwFIjg4jPMTGmXpNCkrNRL5ONGeKyNMiUuP8eUpEMv0dnJpcd2zKpaWr\njycKzgBQ19bNO6cauHpl2oj3uf68eew+3UhV8/Azn40xvFZUw8aFSe7zHUSE7IRI3aug1Azl6/DR\nb4BngHTnz7POa2oGWZ0Vx8ULE3lkRyk9fQ5eOVKNMXDNipGTwnWrrI3r/zg8vLdwsraNsw2dbFk6\nuJS3JgWlZi5fk0KyMeY3xpg+58+jQLIf41J+ctdlC6lq6eKv+8t5obCKrIQIls2zj9h+4ShDSK4d\nzEOTQlZCJGcbOjBmzlY5V2rG8jUp1IvIR0UkyPnzUaDen4Ep/7hkURIr0mP4xfZi3iqu55oVaYx2\nwBHAdefN451Tw4eQXjtWw9I0OxlxEYOuZydE0t7TT0P78D0RSqnpzdek8Ams5ahVQCVwE/BxP8Wk\n/EhE+LfLFnKqvoOefgdXjzJ05HLdecOHkFq6etl9qnFYLwFwL0vVISSlZh5fVx+dNsbcYIxJNsak\nGGNuBHT10Qx13co0shIiSIoOY90o5z275KVEsyR18BDSG8fr6HMYtmpSUGpW8bWn4M2XJi0KNaWC\ng2z86qP5/OrWddhsow8duVy/ylqF9NjOU9aqo2M1xEaEsDZr+FlLmfG6V0GpmWoix3H69mmipqXl\n6THjan/7xhz2n23i238r5J1Tjew8Wcdli5MJDhr+vSIiNIgUe5j2FJSagSbSU9ClJXOIPTyEh2/L\n56tXL+H5gxXUtfV4HTpy0WWpSs1Mo/YURKQV7x/+AkR4ua5mMZtNuHtLHmuz4nhqbzlXLE8dsW12\nQiQFfizVrZTyj1GTgjFm5AXsas66OC+Ji/OSRm2TlRDJ0/vL6elzEBo8kQ6pUmoq6f+tyi+yEyIx\nhnGfzaCUCixNCsovshN1WapSM5EmBeUX851JoajKf+dCK6UmnyYF5Rcp9nAWpUTzr+PDz2vu7Xdo\nXSSlpilNCspvtixNoaC0nnaP8xt6+hxsvvefPPh6SQAjU0qNRJOC8pvNS5Lp7Te8WTzQW9heVEN5\nUyfvnNLlqkpNR35LCiKSJSLbReSIiBSKyD1e2nxERA6KyCEReUtEVvsrHjX18ucnEB0WzPaiWve1\np/eWA3C8ujVQYSmlRjGRMhdj6QO+bIzZKyJ2YI+IvGyMOeLRphS4zBjTKCLXAg8BF/oxJjWFQoNt\nbMpL4vWiGowxtHT28dqxGiJDgyhr7KS9u4+oMH/+J6iUGi+/9RSMMZXGmL3O263AUSBjSJu3jDGN\nzl/fBvSIz1lmy9JkKpq7OF7dxnOHKujpd3DHplwATtS0BTg6pdRQUzKnICI5wFqgYJRmnwT+MRXx\nqKmzeYlVH2l7UQ3b9pazKCWaG9da3w2OV+kQklLTjd/77iISDTwFfMEY43XRuohswUoKm0b4+53A\nnQDZ2dl+ilT5Q2pMOMvnxfCnd85SWtfOv1+zhPmJUYQF23ReQalpyK89BREJwUoIjxtjto3QZhXw\nMPAeY4zXIz6NMQ8ZY/KNMfnJyXo09EyzZWkypXXtiMCNazIIsgl5KdEc1+EjpaYdf64+EuAR4Kgx\n5icjtMkGtgG3GmOO+ysWFVhbnENIG3ITSXee57w41T7h4aPdpxrch/4opSaHP4ePNgK3AodEZL/z\n2jeBbABjzIPAt4FE4BfOw+P7jDH5foxJBcCarDiuWJbKbRfNd19blBrN0/vKae7sJTYiZFyP19Pn\n4L5XjvPL109iDMyLjeDKUcp4j2XP6Ua++pcDfOeGFVy2WHuiam7zW1IwxuxgjNPZjDF3AHf4KwY1\nPQQH2Xj4Y4Nz/ZJUqyp7cU0r6+cn+PxYZxs6+MzjezlU3swt+VnsOdPI958/wqWLkwgLDnI/5ra9\n5Xz+8kWEhwS571tS28YtD73N9efN44tXLCY2MoRXj1Zz9x/20tXr4PWiWk0Kas7TReIqIBY7k0JR\nVdu4ksL3nz9CaV07D350HdesnMfrx2v52K938eibp/i3yxZS0dTJRx/eRVVLF0vS7LxnzcAq6D/v\nLqO+rZvHdp7ib/vLeffqdB4vOMPyeTG0dvVSUqdzHEppmQsVEBlxEUSEBI1rBVJLVy/bj9XygfxM\nrlk5D4DLFidzxbIUfvZaMcU1rdz26120d/eRYg/jyT1l7vs6HIa/7S9n85IUnvvcJSxKtfPYztNc\nvDCRJ+7cwIqMWErr2if9dSo102hSUAFhswmLU6PdScEYw91/2MuPXiwa8T4vHq6ip9/BDavTB13/\n1vXL6e7r5/r7d3CmvoOHbsvnQxdks6O4jspm65CfgtIGKpu7uHFtBsvTY/jTnRt49rOb+PXHzyc6\nLJiFSVGcbeigu6/ffy9aqRlAk4IKmEWpdo5XW0M2T+8r5/mDlTxecJp+h/fVRM8erCQrIYI1WXGD\nrucmRfGJTbn09Du474NruGhhIu9fl4kxsM1Za+mv+8qJCg3iymXWhLSIcF5mLCFB1v8CuclROIw1\nZ6HUXKZJQQXMklQ7dW3dlNa184Pnj2IPD6axo5d9ZxqHta1v6+bN4jrevSod50q1Qb529VLe+vpW\nrjvPGlbKTozkgtwEntpTRldvP38/VMk1K+cRERo07L4AC5KiAThZq0NIam7TpKACZlGq9UH82T/s\npamzl4dvyyfYJrx6rGZY278frqLfYbhhTfqwv4E1HDUvNmLQtZvWZ1JS186PXiyitbuP967N8Hpf\ngJykKACdV1BzniYFFTCuFUiFFS18/OIcLlyQyAW5Cbx6tHpY22f3V7AoJdq9lNUX1503j4iQIB7e\nUUqKPYyLFiaO2DY2IoSk6FBKaie2Aqm7r5/Wrt4JPYZSgaRJQQXMvNhw7OHBpMWE88UrFwOwdWkK\nx6vbBo3tVzZ3sutUAzes9j50NJLosGCuXZkGwHvWpBNkG/2+C5KiJ9xT+MHzR3nXz3boLms1Y2lS\nUAEjItx70yp+det6op3nKlzunAh+zWMI6dkDFQC8e7X3oaPRfPSi+djDg7k5P2vMtrlJURNOCtuL\najhd38Hhcq+1H5Wa9jQpqIC6ZuU8VnusJspNimJBUpR7XuFUXTs/e62YC3IS3OP+47EuO55D/3E1\ni3wYdlqQHEVdWw/Nnec2/FPR1MnZBmsJ7CtehsDGo6Wrl4/9epfOcagpp0lBTTtbl6bw9sl6alu7\n+bff7SHIJvz4Zv+f1Jrr42SzMYZvPX2IH780eE9FQalV5DcpOoxXjw1OCs8eqOBdP3uDvn6HT7Hs\nKmng9eO1vF40fNJdKX/SpKCmna3LUujpd3DLr3ZyvKaV+z+4lqyESL8/74JkazXUWJPNj+08zeMF\nZ3hkRymdPQOb3d4+2UBsRAi3b8zhcHkLVc1dgLWb+r9fOc7h8hYqndfGcriiGYBT9b7vm+ju6/c5\n6Sg1Ek0Kato5PycBe3gwJXXtfOWqJVw6RUXqshMiCbLJqD2Fg2VN/OD5oyxIiqKjp5/tHt/kC0rr\nOT8ngSuc8yKu3sLrJ2opce5/ONvo24f84XJXUvB9+OjmB3fypT8f8Lm9Ut5oUlDTTkiQjdsvzuGW\n/Cw+fdnCKXve0GAbWfER7g/woVq6evnsH/aRGB3Kn++6iKToUJ4/WAlAVXMXp+o72LAggcWp0WTG\nR/DqUSth/HpHKZHOTXNljZ0+xeKaqD7l45yCMYajVa08c6CCghKvZ1Up5RNNCmpa+tJVS/jhTauw\njbGMdLLlJkVRMsIH8X88U0h5UycPfHgtSdFhXLtyHq8eq6ajp889n7BhQSIiwhXLUnmzuI6DZU28\ncaKOT12yABEo9yEp1LZ2U9XSRUx4MGcbO+n1YUioqaOXnj6r3fefP4pjhFIhSo1Fk4JSHnKToimt\naxv2oWqM4eUj1dy0LtNd6vv6VfPo6nXw2rEa3i5pwB4ezLJ5MQBcviyF7j4H9/xxP2HBNj52cQ5p\nMeE+9RRc8wnXrEyj32F8uk91qzVXceXyVA6VN7NtX/m4XrdSLpoUlPKwIDmKrl4HVS2DJ4Qrm7to\n7epjZWas+9r5OQkk28N4/mAlBaX1XJCT4N4gd2FuItFhwZTWtfO+dRkkRIWSGR9BmQ9zCofLrKTg\nquPkyxCSa1L7zksXsDorjntfPEZHT59vL1opD5oUlPKwYIRlqUXO86SXpg3sdwiyCdetTOPVozWU\n1LZz4YKBw4JCg21cujgJgNs35gLWGRLlTb71FHKToliZEes1Fm+qnUksLSacb79rGdUt3fzPv0rH\nvJ9SQ2lSUMrDSMtSi5znPixOGbwJ7vpV6fQ4x/w3LBhcW+lLVy7hxx9Y7a7xlBkfSWVz15jLRg+X\nt7AyI5bEqFDsYcE+rUCqau4GIDUmnPXzE8ifH88bJ2rHvJ9SQ2lSUMpDakwY9vBgjlQOPhGuqKqV\nebHhxEaGDLqePz+e1JgwosOCWe6cT3DJS4nm/esz3b9nxkfQ7zDDhqY8NbT3UN7Uycr0GESEHB9L\nb1S1dJEYFUposPW/dE5SlE+9EqWG0jOalfIgIqzNjmfv6cFnOhRVtbq/8Xuy2YR/v3opjR09BAeN\n/h0rM97agFfW2Om+PZRrf8J5zqGjnKQo9p8dfr7EUNUtXaTGhLt/z4iLoKqli54+hztRKOUL/a9F\nqSHy58dzvKbVXQOpr99BcW3boPkET+9fn8kdlywY83Ez4q3zHkZblupaebQi3UoKuYmRlDd2upeb\njqSquYu02IGkkBkfgTG4jyP1prqli1eOVNPVq0eQqgGaFJQaYv38eIzBfQLcqfoOevocXnsK45Ee\nZ31oj7bE9HB5M9kJke5hqpwk65jQM2McEzq0p+DZKxnJj18q4o7HdrPh/77Kd58t5OQEz5JQs4Mm\nBaWGWJMVh01wDyEdd04yLxmhp+CrsOAgUmPCRl2Wak0yD8xNzE+0VkOdHmWyubuvn/r2HtJiBvcU\ngFGfa//ZJlZmxLAxL4nfv32ad92/g5pR5jvU3KBJQakhosKsTWi7nUnhWFUrNrEmjicqIy5ixG/v\nzR29nGnocC9FBd8qt9a0WCuP0mLD3NfmxYYTZJMRh6rau/sormnj8qWp/PzD6/jHPZfS3dfPIzt0\nGetcp0lBKS/y58ez/2wTff2rHqHmAAAbPklEQVQOjle1kpMYRXhI0IQfNzM+csRVQQfKmoCBSWaA\n+MgQYsIHL0utae0aVPrCtUfBc/goOMg26g7qw+XNOAyszrKeKy8lmnevTuf3b5+mqaPnHF+dmg38\nlhREJEtEtovIEREpFJF7vLQREblfRIpF5KCIrPNXPEqNx7r58XT09HOsqpWi6tYJDx25ZMZHUNHU\nSb+X2kRvnqwjJEhYPz/efU1EyE2K4lSdNQx0vLqVTT/czm/eHPhG71ri6jnRDNbE9khJ4aBz1/Sq\nzIEDjj69eSHtPf08+tapc3txalbwZ0+hD/iyMWY5sAG4W0SWD2lzLbDI+XMn8Es/xqOUz/JzrN3J\nbxbXcaq+fcKTzC6Z8ZH0OYz7272nHSfqWJcdT2To4JXirr0K/Q7Dvz95kJ4+B7tKB5apVruGj2IG\nJ4XRymocLG8mIy6CpOiBIaelaTFcsSyV37x5irbumVEio7imjS/8cR/dfbqCarL4LSkYYyqNMXud\nt1uBo0DGkGbvAR4zlreBOBGZ56+YlPJVemw4aTHh/Gn3WYxhxOWo45XhngAe/A2+ob2HwooWNuUl\nDbtPTmIUFc2dPPj6SfafbSItJty9nwGs4aPQYBuxEYM31mXGR1LV0uW1yurBsqZBw1Qun9mykObO\nXp4oOHNOr2+q/XHXGf66v4LjVbpyarJMyZyCiOQAa4GCIX/KAM56/F7G8MSh1JQTEdbnxLvPVlg8\nicNHAOVNg7/Bv3WyDoBNi4YnhdykKIyxlpBesSyFOy7Jpaqli9pWq4dQ1dxFWkw4IoPLjGfGR+Aw\nA8XyXJo6ejhd38GqrOFJYV12PBcvTOShN0p8KtkN0NnTz7/9bjfFNa1jN55kO4qtf2+l4ziMSI3O\n70lBRKKBp4AvGGNazvEx7hSR3SKyu7ZW67moqbE+2xrbDw22MX+SjgPNiHP2FBoG9xTeLK7DHh7s\n9dv7/ETruaNCg/n+jee5Vye5egtVLV3Dho4AMp3PNfS0N9d8wmqP+QRPt5yfRW1rN8U1vn373ne2\nkRcLq92HCk2V2tZujjkLFZ728TAiNTa/JgURCcFKCI8bY7Z5aVIOZHn8num8Nogx5iFjTL4xJj85\neWqOZlQqP8dKCotSoscsYeGr8JAgku1hg4aPjDG8caKOixYken2exal2MuMj+N6NK0iLDWdFegwi\ncMiZFKpbukiN9ZIURtjA5rrfSi8JCKy5BRioDDuWIxXOU+LGcZ70ZHD1roJsoj2FSeTP1UcCPAIc\nNcb8ZIRmzwC3OVchbQCajTGV/opJqfFYNi+GyNAg94fkZBlaQvtMQwdljZ1eh47A2jex42tbee9a\nq7iePTyE3KQoDpY1Y4xxDh+FDbtfWmw4NhmeFA6cbSI3KWrYHITLguQoQoLE/S18LIXOpDDaBjt/\n2HGijrjIENbPj/f52FI1Nn8WxNsI3AocEpH9zmvfBLIBjDEPAn8HrgOKgQ7gdj/Go9S4hATZeOwT\nF5DuHIaZLJnxEYMmil3j4t4mmUdyXkYsBSUNNHf20t3nGLRHwSU02NqrMHQD28Gy5kFnPwwVEmRj\nYXK0eyf3WAqd9ZpOT2FPwRjDjuI6Ll6YSGxECC8VVk/Zc892fksKxpgdwKgH7BpjDHC3v2JQaqJc\nS1MnU2Z8JC8WVuFwGGw24c3iOtJjw927l31xXkYsf9tfweFy61v60D0KLhlDlqXWtHRR1dI1aH+C\nN4tT7ew5PXZ11s6efopr2ggLtlHR3El3Xz9hwRPf5DeWkrp2Kpu7+FxeMi1dvdS399DS1UtMuPfe\nz3TmOup1y9IUQiZpmHIiAh+BUnPMguQoevsNn/jtO7xdUs9bJ+vZmJc0bPXQaFwT0q8ctb4he5to\nBisBeQ4fDUwye59PcFmSZqe8qZOWrt5R2x2rasFhYPOSZIwZvQDfZNpxYqB3leOsDzVTh5AKShu4\n83d7+Puh6TFyrklBqSn23rUZfOnKxRwsa+aDD71NU0fviPMJI1mREYvIQFLwNnwE1lBVVcvAaW8H\ny5qwyUBp7pG49mUc95hXMMa4h4pcXPMJrvOkp2peYUdxHdkJkWQnRrp7WJ4T3bWt3dzx293sP9s0\nJfFMhKtHtu/M9IhVk4JSUywkyMbnL1/Em1/byvfes4Lrzktjy9KUcT1GdFgwuUlR7m/moyWFfoeh\nsrmL7r5+nt5fzuqsOCJCRx/icZX1KPKYV3j5SDXX37+D148PLAsvrGghNiKEixdaSW0q5hX6+h28\n7exdAWQ7lwt79hReOlLFK0erufXhgmmfGFzVeA+WTY84NSkoFSARoUHcdlEOv/jI+nMaC3cNIXke\nwzmUa1lqeVMnv9t5mrMNnXzpysVjPnZGXAT2sOBBy1JfKKwC4Mk9Ze5rRyqaWZEeQ1J0KNFhwVOS\nFA6UNdPa3eeemI8IDWJebPigpLCrtIHEqFASokOndWIwxrDHeW5HYUWLzxsG/UmTglIzlCspjNRL\ngIHNcofLm7n/1RNctjiZSxaNvddHRFicZncvS+3rd7D9WA0i8FJhFa1dvfT2Ozha1ercNyFkJ0RO\nyfDRW8V1iMDFCxPd13ISo9x7FYwxFJQ0cNHCRJ741AZ3YiiZhocIldS109TRy8a8RLr7HD6v+PIn\nTQpKzVADSWH4HgWXeXHhiMBPXzlBW3cf37huqc+PvzjVTlFVK8YY9p5porGjl09uzKW7z8E/Dldx\nsraNnj6HexNcTlKkzz2Fwopm3jnV4LVa7FgKShtYkmonPirUfc3zuc80dFDV0sWFuQmkx0Xwh09t\noLO3f1APZ7pwDR3dfnEuMLAQIJA0KSg1Q7kmm0dajgrO097s4bR29/GB9Vnj2oi3NM1Oc2cv1S3d\nvHK0mpAg4Z4rFpGbFMW2vWUUOpfDrki3HjM7IYqzjR1jftCfbejg5gd38oEHd3L+D17hq3854PPw\nTm+/gz2nG9mwIHHQ9ZzEKBrae2ju7KWgpAGAC51tMuIiOD8nYcrLcPhi75lGYsKD2bI0hdiIkGkx\nr6BJQakZKjosmO/esIKPXDh/1HaZ8RFEhATxpavGnkvw5DnZ/MqRajYsSMQeHsKNazJ4u6SBl49U\nExESRG6SdSJdTmIkvf2GihEOEQJraOfr2w4C8F/vX8Uli5J4obCKmx/cybMHKsaM6VB5M529/VyQ\nO3j/SE7SwLLUt0vrSYgKZZHHSXmXL0uhqLqVsyOcdV3R1MnNv9o55b2JvaebWJsdT5BNWJUZy4Gz\n2lNQSk3AbRfljFjDyOXfr1nKLz66btS5B29cy1L/caiSkrp2rlqeClhLasGaeF46z06Qzdpfke0s\n3HdmhA9egCd2neXN4nq+ef0ybj4/i59+cC07vraVNdlxfO6JfWMeB7qr1OoFDEsKrr0K9e0UlDRw\nQU7CoH0fVyyzYn/16PCdzyW1bXzgwZ3sKm1g296pSwotXb0cr2l1H6q0KjOWoupWunoDezaEJgWl\nZrkLchPYsmR8S14B4iJDSY0J4ynnB+Xlzg/W7MRI8p0fZCs99jt4fjB7U9bYwQ+eP8LFCxP58AXZ\n7uuxESE89okLuHZlGv/53BHu+eM+XjhcRXPn8I1zBSX1LEyOGnQ4EAxUkn2zuI7yps5hZTxykqJY\nmBzFq8cGDyEVVjRz86920tXbz6a8JA6cbTqneY5zsf9ME8ZY5crBOgWv3zF8L8hU06SglBrRkrQY\nevsNK9JjBtWAeu86q7fgmk8Aa1d1aLCNM0Mmmx0OwxsnavnM43sxwA/fv2rY7u3wkCAe+PA67rx0\nAS8fqeau3+9h7fde4ot/2o9VDQf6HYbdpxq5IHfwfILr/umx4Tx30NoVfKGXNlcsS+Xtknpanbu0\nK5s7+fD/FBAaZOPPd13E+9dn0N7T73N12Inac7oRmwyck+0qZR7oISRNCkqpEbmGkFzDLy43rsng\nU5fkcvWKNPc1m81alurZU3i84DRbfvxPbn1kF2WNnfzXTavIGuFsiiCb8M3rlrH/21fxpzs3cNP6\nTJ7eV86/nCUtjla20Nrdx4YRivnlJEXR0dNPbESI15Pyti5NobffKlNuzMDRpo9/agMLk6Pd39j3\nnhm75tNk2HumkcWpduzOPSppseGk2MMCPtmsSUEpNSLXsterVgxOClFhwXzr+uWDloUCzE8YWBq6\nvaiGbz19mISoUH76wTXs/MZW3rUqfcznDA22ceGCRL5/43lkxEVw3yvHrb0HI8wnuJ/bOXx1fk4C\nNtvwOlLr58cTGxHCK0ereWLXWd44Ucc3r1vqLpORnRBJYlTolCSFfodh/5km93yCy+qsuIAvS/Vn\n6Wyl1Ax3/XnzWJQa7fNS1vmJUewsqae9u4//9fRh8lKi+eOdG86pcmposI3PbFnIt54+zBsn6igo\nqSc7IZJ5sd5LmecmWT2QkXoSwUE2tixJ5pUj1bx4uIqNeYmDVm6JCOvmx09JDaITNa20dve5eycu\nqzNjeflINc2dvSOed+Fv2lNQSo3IZpNx7W3ISYqko6efbz59iPKmTv7v+86bUCntD6zPIj02nP9+\n5TjvnGoYsZcA1klyNmHUHduXL0ulpasPEeGH7181rEexLjue0rp2Gtp7zjlmX7iqvA6dEHeVNPc8\nb2OqaVJQSk0aV3G6v+2v4MMXZnP+BM+jsHoLeexz7qi+cJSkcPHCJHZ96wr3/gpvNi9JJjcpiv+8\ncYW7LpSnddnWh/I+Pw8hvXashsWp0cNiWJMdR0iQsH3IKiljDLf8aie/f/u0X+MCTQpKqUnkWpaa\nYg/ja9f4XlJjNB/Iz2Sec9e2t1VFnoYuVR3KHh7C9q9sdh9tOtSqzDiCbTJoXuG3b53yaWOdNx09\nfbxdUj/oWmtXL7tKG7xWxo0JD2HLkhT+dqDCXe4c4J1TjRSUNhA6BYfwaFJQSk2azPgIrliWyr0f\nWD1pY+JhwUF8590reN/aDLISJvdo1KEiQoNYNi+GvaeteYW3iuv4zjOF/M8bJef0eE/sOssHH3p7\nUBmPN07U0ecwbB1h78j71mVQ29rNWycHkskTu85gDwvmXavnnVMc46FJQSk1aYKDbDz8sXwuWzx2\nJdbxuGZlGj+5Zc24Tqc7V+uy49h/tonmjl6++qRVkqO4pg3HOWxqO+I8hOjRNwd2ar92rIaY8OBh\nK49ctixNISY8mKf3lQPQ2N7D84cquXFtBpGh/l8bpElBKaU8rJsfT2dvP596bDeVzZ3ctD6Tjp5+\nKpoH13T6675yvv/ckVEfq6jaSgrPH6qkpqULh8Pwz6IaLl2cTPAIQ0FhwUFcvyqdFw5X0d7dx7Z9\n5fT0OfiQxy5wf9KkoJRSHlzLRHedauBTly7glvOzADhRM/g8hscLTvPwjlJ2nqwf9hhg7UU4Ud3G\nFctS6XMYfl9whkPlzdS19XD5stHLjrxvXQadvf28WFjFHwpOsyYrjuXpvq8CmwhNCkop5SEzPoK0\nmHAWpUTzxSsWk5dsVVs96ZEUHA7jHhr60UtF7lIcnk7Xt9Pd5+CqFalsXZLCHwpO80JhFSJw2eLR\nk8L67Hgy4yO498UiTta28+ELp6aXAJoUlFJqEBHh93dcwON3XEh4SBDxUaEkRYdyonogKZyqb6e9\np5912XHsOd3I9qLhZzW4aigtTbPz8Y051LX18MgbpazNiiNhyE7woWw24b1rM6hs7rImmFf5f4LZ\n/dxT9kxKKTVD5KXYSfEoNZ6XEs2JmoFCeYXOXsK3372C+YmR3Pvi8WET0UXVrYjAohQ7m/KSyEuJ\npqffwVYvS1G9udFZovy966ZmgtlFk4JSSo0hLyWa4po29zBRYUULIUHC8nkxfOnKxRytbOH5Q5WD\n7lNU1cr8hEgiQoMQEe7YlIsIXLk8zdtTDLMwOZrfffICvnzVkkl/PaPRpKCUUmNYlGKnpauP2tZu\nwDqHYXGqndBgG+9elc7SNDv/7Szc51JU1Tpod/Ut52fxz69sHnXH9VCXLEqe8hpIfksKIvJrEakR\nkcMj/D1WRJ4VkQMiUigit/srFqWUmgjX0Z4nnL2FwooW91kSNpvwiU25lNS2c8hZs6irt59T9e0s\n8agbJSLuSq7TmT97Co8C14zy97uBI8aY1cBm4MciMvrsi1JKBUCeMykU17RR1dJFQ3sPKzxOnbt6\neRohQcLzzkN+imvacBhYkup7r2C68FtSMMb8C2gYrQlgF2uLYrSzbZ+/4lFKqXOVbA8jJjyYEzWt\nHC63JplXZgz0AmIjQ9iUl8RzBysxxnDMufJoPENF00Ug5xQeAJYBFcAh4B5jjGP0uyil1NQTERal\n2jlR3UZhRTMiDCspft158yhv6uRgWTPHq1sJDbaRk+j9lLnpLJBJ4WpgP5AOrAEeEBGvW/ZE5E4R\n2S0iu2tra6cyRqWUAqx5heKaNgorWshNiiIqbPAy0atcQ0iHKjlW1UpecvSIpSyms0BGfDuwzViK\ngVLAa61dY8xDxph8Y0x+cvLkFtpSSilf5KVEU9/ew67ShkHzCS6xkSFcsiiZ5w9WUlTV4vWc6Jkg\nkEnhDHA5gIikAkuAc6tPq5RSfuaabG7u7GXlCHWIXENI1S3dM3I+Afx4RrOIPIG1qihJRMqA7wAh\nAMaYB4H/BB4VkUOAAF8zxtT5Kx6llJqIRR4ribz1FACuXJ5KSJDQ229YrElhMGPMh8b4ewVwlb+e\nXymlJlN6bDiRoUF09PS79ygMFRsRwqWLknn1WM2MHT6auoIaSik1g4mINa/Q1kP8KAXtPrNlobvS\n6kykSUEppXz0ua2L6OgZfTvV+vkJrJ+fMEURTT5NCkop5aMrl6cGOgS/m3mLaJVSSvmNJgWllFJu\nmhSUUkq5aVJQSinlpklBKaWUmyYFpZRSbpoUlFJKuWlSUEop5SaeB03PBCJSC5w+x7snAXOx6N5c\nfN1z8TXD3Hzdc/E1w/hf93xjzJhnD8y4pDARIrLbGJMf6Dim2lx83XPxNcPcfN1z8TWD/163Dh8p\npZRy06SglFLKba4lhYcCHUCAzMXXPRdfM8zN1z0XXzP46XXPqTkFpZRSo5trPQWllFKjmDNJQUSu\nEZEiESkWka8HOh5/EJEsEdkuIkdEpFBE7nFeTxCRl0XkhPOf8YGO1R9EJEhE9onIc87fc0WkwPme\n/0lERj4uawYSkTgReVJEjonIURG5aC681yLyRed/34dF5AkRCZ+N77WI/FpEakTksMc1r++vWO53\nvv6DIrLuXJ93TiQFEQkCfg5cCywHPiQiywMblV/0AV82xiwHNgB3O1/n14FXjTGLgFedv89G9wBH\nPX7/IfDfxpg8oBH4ZECi8p+fAi8YY5YCq7Fe+6x+r0UkA/g8kG+MWQkEAR9kdr7XjwLXDLk20vt7\nLbDI+XMn8MtzfdI5kRSAC4BiY0yJMaYH+CPwngDHNOmMMZXGmL3O261YHxIZWK/1t85mvwVuDEyE\n/iMimcD1wMPO3wXYCjzpbDKrXreIxAKXAo8AGGN6jDFNzIH3GuvEyAgRCQYigUpm4XttjPkX0DDk\n8kjv73uAx4zlbSBOROady/POlaSQAZz1+L3MeW3WEpEcYC1QAKQaYyqdf6oCZuOZgvcB/w44nL8n\nAk3GGNeBurPtPc8FaoHfOIfMHhaRKGb5e22MKQd+BJzBSgbNwB5m93vtaaT3d9I+4+ZKUphTRCQa\neAr4gjGmxfNvxlpuNquWnInIu4AaY8yeQMcyhYKBdcAvjTFrgXaGDBXN0vc6HutbcS6QDkQxfIhl\nTvDX+ztXkkI5kOXxe6bz2qwjIiFYCeFxY8w25+VqV1fS+c+aQMXnJxuBG0TkFNbQ4Fas8fY45xAD\nzL73vAwoM8YUOH9/EitJzPb3+gqg1BhTa4zpBbZhvf+z+b32NNL7O2mfcXMlKbwDLHKuUAjFmph6\nJsAxTTrnOPojwFFjzE88/vQM8DHn7Y8Bf5vq2PzJGPMNY0ymMSYH6719zRjzEWA7cJOz2ax63caY\nKuCsiCxxXrocOMIsf6+xho02iEik87931+uete/1ECO9v88AtzlXIW0Amj2GmcZlzmxeE5HrsMad\ng4BfG2N+EOCQJp2IbALeAA4xMLb+Tax5hT8D2VgVZm82xgydwJoVRGQz8BVjzLtEZAFWzyEB2Ad8\n1BjTHcj4JpOIrMGaWA8FSoDbsb7ozer3WkS+C9yCtdpuH3AH1vj5rHqvReQJYDNWNdRq4DvAX/Hy\n/joT5ANYQ2kdwO3GmN3n9LxzJSkopZQa21wZPlJKKeUDTQpKKaXcNCkopZRy06SglFLKTZOCUkop\nN00KasYTkX4R2e/xM2lF4EQkx7NK5Tncf62IPOK8vVREdopIt4h8ZUg7r1V8x1P9U0TOE5FHzzVW\npUCTgpodOo0xazx+/l+gA/LwTeB+5+0GrAqfP/JsMEYVX5+rfxpjDgGZIpI9qa9AzSmaFNSsJSKn\nROS/ROSQiOwSkTzn9RwRec1Zd/5V14eoiKSKyNMicsD5c7HzoYJE5H+cNfxfEpEIZ/vPi3V2xUER\n+aOX57cDq4wxBwCMMTXGmHeA3iFNvVbxHa3Sq4h8QKzzBA6IyL88HutZrF3dSp0TTQpqNogYMnx0\ni8ffmo0x52Ht9rzPee1nwG+NMauAxxn4Jn8/8LoxZjVWHaFC5/VFwM+NMSuAJuD9zutfB9Y6H+cu\nL3HlA74MPY1U4XK0Sq/fBq52xnqDx313A5f48JxKeaVJQc0GQ4eP/uTxtyc8/nmR8/ZFwB+ct38H\nbHLe3orzcBJjTL8xptl5vdQYs995ew+Q47x9EHhcRD6KVXJhqHlY5a394U3gURH5FFbpFpcarOqh\nSp0TTQpqtjMj3B4Pzxo6/Vhlq8E61OfnWL2KdzyqdLp0AuE+PP5IFS7rGaH6pzHmLuB/Oe+3R0QS\nnW3Cnc+r1DnRpKBmu1s8/rnTefstBsbdP4JVRBCs4w0/De7znmNHelARsQFZxpjtwNeAWCB6SLOj\nQJ4PMXqt4uusl++1+qeILDTGFBhjvo3VG3EllcX4NmSllFdDv9koNRNFiMh+j99fMMa4lnXGi8hB\nrG/7H3Je+xzWiWVfxfpAvd15/R7gIRH5JFaP4NNYp3t5EwT83pk4BLjfeRymmzHmmIjEiojdGNMq\nImlYY/4xgENEvgAsN8a0iMhngRcZqOLrms/4GvBHEfk+VvXPR5zX7xWRRc7nfhU44Ly+BXh+7H9l\nSnmnVVLVrOU8dCffGFMXwBi+CLQaYx6egucKA14HNnlMTis1Ljp8pJR//ZLBcxL+lA18XROCmgjt\nKSillHLTnoJSSik3TQpKKaXcNCkopZRy06SglFLKTZOCUkopN00KSiml3P4/zilEWQOzLy8AAAAA\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0cchH6PLG-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 5. Step - Predict!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlAAnsgWLKAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "19ff19f7-0528-43d2-fe98-97b9208d3b8d"
      },
      "source": [
        "input_line = \"Daniele\"\n",
        "model_remote = model_pointers[\"alice\"]\n",
        "line_tensor = lineToTensor(input_line)\n",
        "line_tensor\n",
        "line_remote = line_tensor.send(alice)\n",
        "hidden = model_remote.initHidden()\n",
        "hidden_remote = hidden.copy().send(alice)\n",
        "hidden_remote\n",
        "with torch.no_grad():\n",
        "    for i in range(line_remote.shape[0]):\n",
        "        output, hidden_remote = model_remote(line_remote[i], hidden_remote)\n",
        "        \n",
        "n_predictions = 3\n",
        "topv, topi = output.copy().get().topk(n_predictions, 1, True)\n",
        "topv\n",
        "\n",
        "predictions = []\n",
        "\n",
        "\n",
        "for i in range(n_predictions):\n",
        "            value = topv[0][i].item()\n",
        "            category_index = topi[0][i].item()\n",
        "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
        "            predictions.append([value, all_categories[category_index]])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(-1.88) French\n",
            "(-2.20) Dutch\n",
            "(-2.22) Italian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZnx7U_bLNUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, input_line, worker, n_predictions=3):\n",
        "    model = model.copy().get()\n",
        "    print('\\n> %s' % input_line)\n",
        "    model_remote = model.send(worker)\n",
        "    line_tensor = lineToTensor(input_line)\n",
        "    line_remote = line_tensor.copy().send(worker)\n",
        "    #line_tensor = lineToTensor(input_line)\n",
        "    #output = evaluate(model, line_remote)\n",
        "    # Get top N categories\n",
        "    hidden = model_remote.initHidden()\n",
        "    hidden_remote = hidden.copy().send(worker)\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        for i in range(line_remote.shape[0]):\n",
        "            output, hidden_remote = model_remote(line_remote[i], hidden_remote)\n",
        "        \n",
        "    topv, topi = output.copy().get().topk(n_predictions, 1, True)\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(n_predictions):\n",
        "        value = topv[0][i].item()\n",
        "        category_index = topi[0][i].item()\n",
        "        print('(%.2f) %s' % (value, all_categories[category_index]))\n",
        "        predictions.append([value, all_categories[category_index]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JBZLFbrLP3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "01a48078-4d0a-42a6-c995-b60ade59a429"
      },
      "source": [
        "predict(model_pointers[\"alice\"], \"Qing\", alice)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Qing\n",
            "(-1.20) Chinese\n",
            "(-1.23) Vietnamese\n",
            "(-1.54) Korean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhugkGySLRpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}